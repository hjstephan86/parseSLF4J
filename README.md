# parseSLF4J

This is a simple java project to parse the SLf4J log files generated by [https://github.com/hjstephan86/bible-app](https://github.com/hjstephan86/bible-app). It gives a detailed description for semi-automated log file analysis and explains how to fetch, process, filter, and analyze logs from both Papertrial and Heroku using a combination of Bash, AWK, Java, and Python.

## Error: Log File Analysis

In [https://github.com/hjstephan86/blogg?tab=readme-ov-file#Verfolgung](https://github.com/hjstephan86/blogg?tab=readme-ov-file#Verfolgung) I describe a problem when running the semi-automated log file analysis. Unfortunately, due to some strange reason the analysis is currently not possible. 

As of 2025-07-10 the JSON format contained invalid keys for plain JSON to Java conversion:

| Invalid Key             | Valid Java Field Name   |
| ----------------------- | ----------------------- |
| `sw.token.signature`    | `sw_token_signature`    |
| `host.name`             | `host_name`             |
| `sw.remote.ip`          | `sw_remote_ip`          |
| `sw.log_destination.id` | `sw_log_destination_id` |

Here is an example response: 

```
{"receive_time":"2025-07-10T19:40:38.357Z","event_id":"1880051535950323712","sw.token.signature":"phX8IdfySSOKnnBT7v6UPwp5Z1BkLgjnA1g7-622sdY","syslog_host":"bible-app","sender_ip_str":"34.254.1.154","sw.remote.ip":"34.254.1.154","syslog_appname":"heroku/router","loghdr":"<134>1 2025-07-10T19:40:38.262688+00:00 host heroku router - ","logmsg":"at=info method=GET path=\"/\" host=www.123-bibel.de request_id=dac2fae7-ca20-0aa2-7707-62fe87f1aa6a fwd=\"20.191.45.212\" dyno=web.1 connect=0ms service=3ms status=200 bytes=3026 protocol=http1.1 tls=false","sw.log_destination.id":189736,"syslog":{"priority":"134","timestampMillis":1752176438262,"timestamp":"2025-07-10T19:40:38.262688+00:00","host":"host","appName":"heroku","procId":"router","severity":"Informational","facility":"local use 0"},"syslog_message":"-","heroku":{"at":"info","method":"GET","path":"/","host":"www.123-bibel.de","request_id":"dac2fae7-ca20-0aa2-7707-62fe87f1aa6a","fwd":"20.191.45.212","destinationDyno":"web.1","connect":"0ms","service":"3ms","status":"200","bytes":"3026","protocol":"http1.1","tls":"false","dyno":"router","source":"heroku","connectMs":0,"serviceMs":3},"syslog_priority":134,"sender_ip":587071898,"host.name":"bible-app","time":1752176438262,"source_name":"bible-app"}
```

The downloaded archives from Papertrail for the time from 2025-07-10 to 2025-07-18 are located here: [https://github.com/hjstephan86/blogg/tree/main/doc/CIA/Papertrail/json.gz](https://github.com/hjstephan86/blogg/tree/main/doc/CIA/Papertrail/json.gz). Unfortunately, it was not possible for me to download them using the Papertrail API.

## Log File Analysis

This is how the semi-automated log file analysis works:

### 1. Analyze Papertrail and Heroku Logs
```bash
# Fetch Papertrail logs and extract the second column
papertrail bible-app | cut -f2

# Combine Papertrail log files into a single file
cat plogs-2025-06-21-22-00-01.txt plogs-2025-06-28-22-00-01.txt > plogs-2025-06-28.txt

# Fetch Heroku logs, strip metadata (first 45 characters), and save to a file
heroku logs --app bible-app --source app | cut -c46- > hlogs-2025-06-22.txt

# Run Java log parser with both Papertrail and Heroku logs
java -jar target/SLF4J-parser-1.0.0-jar-with-dependencies.jar -a plogs-2025-06-21.txt hlogs-2025-06-22.txt
```

### 2. Filter and Sort
```bash
# Skip the first 7 lines, extract the 6th column (e.g. country), count unique values, sort descending
awk 'NR>7 {print $6}' logs-output-2025-06-22.txt | sort | uniq -c | sort -nr

# Exclude entries from specific countries
grep -v "United States" logs-output-2025-06-22.txt | grep -v "Germany"

# Extract and sort unique region and city pairs
awk '{print $2, $3}' regions.txt | sort -u
```

### Alternative: Quick Python Analysis
```bash
# Extract IPs from "requested" log entries
heroku logs --app bible-app --source app | cut -c46- | grep requested | awk '{print $12}' | uniq > ips.txt

# Process the extracted IPs with a Python script
python3 ips.py ips.txt
```

## Requests World Wide
Interesting to observe that within 140 days from initial deployment on October 2024, 22/10/2024, until March 2025, 11/03/2025, users from 33 countries and 5 continents requested [https://www.123-bibel.de](https://www.123-bibel.de):
Austria, 
Bangladesh,
Belgium, 
Brazil, 
Cambodia, 
Canada, 
China, 
Finland, 
France, 
Germany, 
Hong Kong,
India, 
Indonesia, 
Ireland, 
Italy, 
Japan, 
Lithuania, 
Moldova, 
Netherlands, 
Poland, 
Russia, 
Singapore, 
Slovakia, 
South Africa,
South Korea,
Spain, 
Sweden, 
Switzerland, 
Thailand,
TÃ¼rkiye, 
Ukraine, 
United Kingdom,
United States.

This list of countries is just an overview but leading countries with a high request demand are the United States, United Kingdom and Germany.